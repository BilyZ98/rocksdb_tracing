

Successfully run the example code from wiki of rocksdb.

I modify the cmakelist file to add build code of trace_example.

I parse the  io_trace log file and see the output of it .

Quite clear. 
The following is the output of this command 
`./io_tracer_parser -io_trace_file /tmp/binary_trace_test_example`

```
Start Time: 1658334582533914
RocksDB Major Version: 7
RocksDB Minor Version: 6
Access Time : 116743265191870     , File Name: 000028.log          , File Operation: GetFileSize       , Latency: 971       , IO Status: OK, File Size: 0

```

So I will check out some block cache tracing doc today and run the code maybe ? 

 I allocate two hours for this task. Let's see where we head .


 So now I am trying to run the db_bench
 with tracing enabled, but I don't know how to parse the trace results .

I learn the following trace_analyzer command from the wiki.
```
./trace_analyzer -analyze_get -output_access_count_stats -output_dir=/tmp/trace_dir -output_key_stats -output_qps_stats -convert_to_human_readable_trace -output_value_distribution -output_key_distribution -print_overall_stats -print_top_k_access=3 -output_prefix=test -trace_path=/tmp/test_trace.log
```


Too much options !!
I could see the distribution of the keys and qps. There is also a human_readable trace file under the directory.

I now think about that I can use some shell command recorder yongfeng said.


Below is another example that will write the time series human readable data to file.
```


./trace_analyzer -analyze_get -analyze_put -analyze_merge -analyze_delete \
-analyze_single_delete -analyze_iterator -analyze_multiget \
-output_access_count_stats -output_dir=./result -output_key_stats -output_qps_stats \
-output_value_distribution -output_key_distribution -output_time_series -print_overall_stats \
-print_top_k_access=3 -value_interval=1 -output_prefix=trace_test -trace_path=./trace_example
```


So really what I want is the get latency series data to plot figure.
And Block Cache ? 

Now all I know about the trace is that it record every get/put/delete ops latency maybe ?

So what about the block_cache tracing ?


Trace level 
-  Application op trace 
-   Block Cache trace 
- FileSystem IO trace.

Let me check out the paper again.

Emm, the paper use block_read , block_cache_hit read_bytes, write_bytes characteristics. 

so block_read and block_cache_hit -> Block Cache trace 

and read_bytes, write_bytes -> application op trace.


So what we want is a benchmark  that  will better simulate the block cache and file_system io calling . 


The method could be improved, we need to do some experiments to observe more.


So I just read the two wiki docs of rocksdb 
1. Block cache analysis and simulation tools

  This teaches how you can use `block_cache_analyzer` tool to analyze your block cache trace file

  And it also have some code examples .
2.   Rocskdb trace, replay, analyzer, and workload generation.
  Trace example for get/delete/put op .
  How to write replay code 
  `trace_analyzer` command introduction.


3. IO Trace and Parser 
 Info from this tracer 
 - Access timestamp in micros
 - File operation (append, read )
 - latency 
 - Filename 


I have plenty of options to do now. 
1.  write the test code example
2. run the db_bench with trace and block trace, then do some plot 
3. Do I need to check out the source code tracing . It will be fun to do this check, and it will be more fun to think about how I can implement this functionality .



Three trace interface for `DB`

1. `virtual Status StartTrace(const TraceOptions& /*options*/, std::unique_ptr<TraceWriter>&& /*trace_writer*/) `
2. `virtual Status StartBlockCacheTrace(
      const TraceOptions& /*options*/, std::unique_ptr<TraceWriter>&& /*trace_writer*/) 
`
3. `virtual Status StartIOTrace(const TraceOptions& /*options*/, std::unique_ptr<TraceWriter>&& /*trace_writer*/) 
`

And all the trace info will be written to trace file.
The difference is that what kind of trace_analyzer will be used to parse the info, `block_cache_trace_analyzer` or `trace_analyzer`

